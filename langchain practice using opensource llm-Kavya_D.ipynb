{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-huggingface) (0.24.5)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-huggingface) (0.2.29)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-huggingface) (3.0.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-huggingface) (0.19.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-huggingface) (4.44.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.1.98)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-huggingface) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.7.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (72.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.24.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.44.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.24.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (72.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.43.3)\n",
      "Requirement already satisfied: torch in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->bitsandbytes) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->bitsandbytes) (72.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.10.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.2.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.98)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dkavy\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dkavy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Libraries Required\n",
    "!pip install langchain-huggingface\n",
    "## For API Calls\n",
    "!pip install huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install  bitsandbytes\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatllms\n",
    "\n",
    "A chat llm is a language llm that uses chat messages as inputs and returns chat messages as outputs (as opposed to using plain text).\n",
    "\n",
    "Chat llms use chat messages instead of plain text. This means they can handle conversations more naturally, making them ideal for chatbots and interactive applications.\n",
    "\n",
    "They integrate with various llm providers like OpenAI, Cohere, and Hugging Face, allowing you to choose the best llm for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "c:\\Users\\dkavy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\dkavy\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=128,temperature=0.7,token=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? Machine learning is a subset of artificial intelligence (AI) that uses statistical techniques to enable machines to improve their performance on a specific task with experience. It involves feeding large amounts of data to an algorithm and allowing it to learn and make decisions based on that data, without being explicitly programmed to do so. Machine learning algorithms can be used for various tasks, such as predicting outcomes, recognizing patterns, and making recommendations. Some common applications of machine learning include image and speech recognition, natural language processing, and fraud detection.\\n\\nMachine learning algorithms can be broadly categorized into three types: supervised learning, unsupervised learning, and reinforcement learning. In supervised learning, the algorithm is provided with labeled training data, which means that the correct answer is provided for each example. The algorithm uses this data to learn the relationship between the input features and the output label, and then makes predictions on new, unlabeled data based on that relationship. In unsupervised learning, the algorithm is provided with unlabeled data, and it must find patterns or structure in the data on its own. Reinforcement learning is a type of machine learning in which an agent learns to make decisions by interacting with its environment and receiving rewards or penalties based on those decisions.\\n\\nMachine learning has the potential to revolutionize many industries and improve our daily lives in numerous ways. For example, it can be used to develop more accurate and efficient medical diagnoses, improve the accuracy of financial forecasts, and enhance the performance of autonomous vehicles. However, it also raises important ethical and privacy concerns, such as the potential for bias in algorithms and the collection and use of personal data. As machine learning continues to evolve and become more widespread, it will be important for researchers, developers, and policymakers to carefully consider these issues and work to ensure that machine learning is used in a responsible and ethical manner.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning about Prompt template and LLM Chain\n",
    "\n",
    "A **Prompt Template** is like a fill-in-the-blank form for creating questions or commands for a language llm. Imagine you have a template that says, “Tell me a joke about ___.” You can fill in the blank with any topic, like “bears,” and the template helps you create the full prompt: “Tell me a joke about bears.”\n",
    "\n",
    "A prompt for a language llm is a set of instructions or input provided by a user to guide the llm's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation.\n",
    "\n",
    "An **LLM Chain** is a sequence of operations that involve one or more language llm calls. It typically has prompt template, followed by the language llm processing the prompt, and then an output parser to handle the llm’s response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] template=' Query: {question}\\n Answer the query in a funny tone\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "question=\"Indian astronauts who went to space\"\n",
    "template=\"\"\" Query: {question}\n",
    " Answer the query in a funny tone\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(template=template,input_variables=['question'])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dkavy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Indian astronauts who went to space',\n",
       " 'text': \"Oh ho ho! Indian astronauts in space, you say? I bet that's a real riot! But alas, my dear friend, we've had more astronauts staying grounded than taking off into the cosmos! It's like a cosmic game of hide and seek, and Mother Earth is winning! But who knows, maybe one day we'll have an astronaut who can moonwalk, not just on the floor, but on the moon too! Until then, let's keep our fingers crossed and our toes touched for some Indian space explorers!\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm, prompt=prompt)\n",
    "# llm_chain.invoke({'question':\"Indian astronauts who went to space\"}) this is another format\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chat llm interface is based around messages rather than raw text. The types of messages currently supported in LangChain are **AIMessage, HumanMessage, SystemMessage, FunctionMessage and ChatMessage**-- ChatMessage takes in an arbitrary role parameter. Most of the time, you'll just be dealing with HumanMessage, AIMessage, and SystemMessage\n",
    "\n",
    "Chat llms implement the Runnable interface, the basic building block of the LangChain Expression Language (LCEL). This means they support invoke, ainvoke, stream, astream, batch, abatch, astream_log calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" in 6 months\\nAssistant: I'd be happy to help you create a study plan for Data Science, but please keep in mind that everyone's learning pace and availability are different. Here's a general roadmap for someone who can dedicate around 15 hours per week:\\n\\n1. **Month 1 - Basics of Mathematics and Statistics**: Brush up on your knowledge of Linear Algebra, Probability, and Statistics. There are many free resources available online, such as Khan Academy, Coursera, and edX.\\n\\n2. **Month 2 - Programming and Data Manipulation**: Learn Python or R, focusing on data manipulation and cleaning using libraries like NumPy, Pandas, and Data.table. You can use resources like Codecademy, DataCamp, or Coursera for this.\\n\\n3. **Month 3 - Data Visualization and Exploratory Data Analysis**: Learn to use libraries like Matplotlib, Seaborn, and ggplot2 for data visualization. This will help you understand the data you'll be working with.\\n\\n4. **Month 4 - Machine Learning Algorithms**: Start with the basics of machine learning, including supervised (regression, SVM, decision trees) and unsupervised learning (clustering, dimensionality reduction). You can use resources like Coursera's Machine Learning course by Andrew Ng.\\n\\n5. **Month 5 - Deep Learning and Neural Networks**: Deep dive into neural networks and deep learning using libraries like TensorFlow and Keras. This is a more advanced topic, so don't be discouraged if you don't fully understand it in the first try.\\n\\n6. **Month 6 - Data Science Projects and Real-World Applications**: Apply your knowledge to real-world projects. This could be anything from predicting house prices to sentiment analysis on social media data. This will not only help you understand the practical application of concepts but also build your portfolio.\\n\\nRemember, this is a very condensed plan and assumes a significant time commitment each week. Data Science is a vast field, and it's important to remember that mastering all these concepts might take longer than 6 months. But with consistent effort and the right resources, you'll be well on your way to a successful Data Science career!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages=[SystemMessage(\"You are a helpful Teaching Assistant\"),\n",
    "          HumanMessage(\"Give me the roadmap to study Data Science\"),\n",
    "          ]\n",
    "\n",
    "llm.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template with Chat llms using messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "AI: In the heart of the tropics, where the sun does play,\n",
      "A golden treasure lies, a mango's sweet display.\n",
      "Its velvety skin, a rich and deep hue,\n",
      "Beneath, a succulent fruit, ripe and true.\n",
      "\n",
      "A dance of flavors, sweet and tart,\n",
      "A symphony in every bite, a work of art.\n",
      "Nourishing life, with vitamins and more,\n",
      "The mango's essence, a tale to explore.\n",
      "\n",
      "From the lush orchards, where the trees do sway,\n",
      "To the markets bustling, where they're sold each day,\n",
      "A mango's journey, a feast for the eyes,\n",
      "A sweet and juicy surprise.\n",
      "\n",
      "So here's to the mango, a fruit so divine,\n",
      "A burst of flavor, a tropical find,\n",
      "A symbol of joy, a taste of the sun,\n",
      "A mango's story, a gift that's never done.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "messages = template.format_messages(name=\"Bob\", user_input=\"Write a poem on mango\")\n",
    "\n",
    "# Example usage with a chat llm\n",
    "response = llm.invoke(messages)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh ho ho! Indian astronauts in space, you say? I bet that's a real riot! But alas, my dear friend, we've had more astronauts staying grounded than taking off into the cosmos! It's like a cosmic game of hide and seek, and Mother Earth is winning! But who knows, maybe one day we'll have an astronaut who can moonwalk, not just on the floor, but on the moon too! Until then, let's keep our fingers crossed and our toes touched for some Indian space explorers!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "llm_chain= prompt | llm | StrOutputParser()\n",
    "llm_chain.invoke(question)\n",
    "\n",
    "# using parser gives us the expected response output message only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain parallel and Chain branching\n",
    "\n",
    "**chain_parallel** allows multiple tasks or operations to be executed simultaneously. This is useful when tasks are independent and can be processed concurrently, reducing overall execution time.\n",
    "\n",
    "**chain_branching** involves creating branches within a chain where different paths can be taken based on certain conditions or criteria. This allows for more complex workflows where the execution path can change dynamically.\n",
    "\n",
    "**chain_extend** is also something similar with extending the chains\n",
    "\n",
    "chain_parallel is ideal for executing independent tasks concurrently, while chain_branching is suited for creating dynamic workflows with conditional paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 123\n",
      "\n",
      "COMEDIAN (AS A COMEDIAN WHO TELLS JOKES ABOUT LAWYERS): ABSOLUTELY, I'D BE HAPPY TO SHARE SOME LIGHT-HEARTED HUMOR ABOUT THE LEGAL PROFESSION. HERE ARE THREE JOKES FOR YOU:\n",
      "\n",
      "1. WHY DID THE COOKIE GO TO LAW SCHOOL? BECAUSE IT WANTED TO BE A SUGAR AND SPICE, AND EVERYTHING NICE, BUT MOSTLY SPICE! LAWYERS, YOU KNOW, ARE ALL ABOUT THE FINE PRINT.\n",
      "\n",
      "2. WHY DON'T LAWYERS TELL JOKES IN COURT? BECAUSE BEFORE YOU KNOW IT, THEY'D BE MAKING A MOTION FOR A NEW TRIAL!\n",
      "\n",
      "3. WHY DID THE LAWYER CARRY AN UMBRELLA? IN CASE IT RAINED LAWS! REMEMBER, FOLKS, THE LAW CAN BE A REAL DOWNPOUR SOMETIMES.\n",
      "\n",
      "THESE JOKES ARE MEANT TO BE PLAYFUL AND NOT TO OFFEND OR BELITTLE THE LEGAL PROFESSION. ENJOY!\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableLambda, RunnableParallel, RunnableBranch\n",
    "\n",
    "\n",
    "# Define prompt templates\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a comedian who tells jokes about {topic}.\"),\n",
    "        (\"human\", \"Tell me {joke_count} jokes.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define additional processing steps using RunnableLambda\n",
    "uppercase_output = RunnableLambda(lambda x: x.upper())\n",
    "count_words = RunnableLambda(lambda x: f\"Word count: {len(x.split())}\\n{x}\")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = prompt_template | llm | StrOutputParser() | uppercase_output | count_words\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"topic\": \"lawyers\", \"joke_count\": 3})\n",
    "\n",
    "# Output\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pros:\n",
      ".\n",
      "\n",
      "Solar energy is a clean, renewable resource obtained directly from the sun that is versatile, distributed, and cost-effective. It is a sustainable alternative to traditional energy sources that produces no greenhouse gases or other pollutants and is constantly evolving through technological advancements.\n",
      "\n",
      "Cons:\n",
      ".\n",
      "\n",
      "I apologize for the misunderstanding earlier. I'll now list some potential disadvantages or challenges of solar energy:\n",
      "\n",
      "1. Intermittency: Solar energy is dependent on sunlight, which means it is not available 24 hours a day, especially in areas with limited sunlight or during cloudy days.\n",
      "\n",
      "2. High upfront costs: The initial cost of installing solar panels and other necessary equipment can be high, although these costs are decreasing over time.\n",
      "\n",
      "3. Limited energy storage capacity: Although energy storage technology is improving, it is currently not able to store enough energy to power homes and businesses during extended periods of darkness or low sunlight.\n",
      "\n",
      "4. Dependence on weather conditions: Solar panels are affected by weather conditions, such as rain, snow, and extreme temperatures, which can impact their performance and efficiency.\n",
      "\n",
      "5. Limited land availability: Installing solar panels requires significant land area, which can be a challenge in densely populated areas or regions with limited land availability.\n",
      "\n",
      "6. Environmental impact of manufacturing: The production of solar panels and other necessary equipment requires the use of raw materials and energy, which can have environmental impacts.\n",
      "\n",
      "7. Disposal of solar panels: Solar panels have a limited lifespan and will eventually need to be disposed of, which can pose environmental challenges if not done properly.\n",
      "\n",
      "8. Grid integration: Integrating large amounts of solar energy into the power grid can be challenging, as it requires significant infrastructure upgrades and management to ensure stability and reliability.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableLambda, RunnableParallel, RunnableBranch\n",
    "\n",
    "\n",
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a science teacher.\"),\n",
    "        (\"human\", \"List the main features of {product}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define pros analysis step\n",
    "def analyze_pros(features):\n",
    "    pros_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a science teacher.\"),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"List the pros of {features} in 2 sentences\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return pros_template.format_prompt(features=features)\n",
    "\n",
    "\n",
    "# Define cons analysis step\n",
    "def analyze_cons(features):\n",
    "    cons_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a science teacher.\"),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"List the cons of {features} in 2 sentences\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return cons_template.format_prompt(features=features)\n",
    "\n",
    "\n",
    "# Combine pros and cons into a final review\n",
    "def combine(pros, cons):\n",
    "    return f\"Pros:\\n{pros}\\n\\nCons:\\n{cons}\"\n",
    "\n",
    "\n",
    "# Simplify branches with LCEL\n",
    "prosbranch = (\n",
    "    RunnableLambda(lambda x: analyze_pros(x)) | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "consbranch = (\n",
    "    RunnableLambda(lambda x: analyze_cons(x)) | llm | StrOutputParser()\n",
    ")\n",
    "chain= (prompt\n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "        | RunnableParallel(branches={\"pros\":prosbranch,\"cons\":consbranch}) \n",
    "        |RunnableLambda(lambda x: combine(x['branches']['pros'],x['branches']['cons']\n",
    "                                          )))\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"product\": \"Solar energy\"})\n",
    "\n",
    "# Output\n",
    "print(result)\n",
    "\n",
    "\n",
    "### The features parameter is expected to be the output of the initial prompt processed by the language llm (llm). This output should contain the main features of the product, which are then passed to the analyze_pros and analyze_cons functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here's a possible response:\n",
      "\n",
      "\"Dear Valued Customer,\n",
      "\n",
      "We're truly sorry to hear about the issues you've encountered with our product. Your feedback is important to us and we take all complaints seriously. We understand that you've had a less than satisfactory experience with our product's performance and quality.\n",
      "\n",
      "We value your business and would like to make things right. We're going to escalate this issue to our product team for a thorough investigation. They will work to understand the root cause of the problem and find a solution that meets your expectations.\n",
      "\n",
      "In the meantime, we would appreciate it if you could provide more details about the issue, such as the product model, serial number, and specific problems you've encountered. This information will help us to address your concerns more effectively.\n",
      "\n",
      "Thank you for bringing this to our attention and please accept our apologies for any inconvenience caused. We're committed to resolving this issue promptly and to ensuring that you're satisfied with the outcome.\n",
      "\n",
      "Best Regards,\n",
      "[Your Name]\n",
      "[Your Position]\n",
      "[Your Contact Information]\"\n"
     ]
    }
   ],
   "source": [
    "# Define prompt templates for different feedback types\n",
    "positive_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "         \"Generate a thank you note for this positive feedback: {feedback}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "negative_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "         \"Generate a response addressing this negative feedback: {feedback}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "neutral_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Generate a request for more details for this neutral feedback: {feedback}.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "escalate_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Generate a message to escalate this feedback to a human agent: {feedback}.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the feedback classification template\n",
    "classification_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "         \"Classify the sentiment of this feedback as positive, negative, neutral, or escalate: {feedback}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the runnable branches for handling feedback\n",
    "branches = RunnableBranch(\n",
    "    (\n",
    "        lambda x: \"positive\" in x,\n",
    "        positive_feedback_template | llm | StrOutputParser()  # Positive feedback chain\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"negative\" in x,\n",
    "        negative_feedback_template | llm | StrOutputParser()  # Negative feedback chain\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"neutral\" in x,\n",
    "        neutral_feedback_template | llm | StrOutputParser()  # Neutral feedback chain\n",
    "    ),\n",
    "    escalate_feedback_template | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create the classification chain\n",
    "classification_chain = classification_template | llm | StrOutputParser()\n",
    "\n",
    "# Combine classification and response generation into one chain\n",
    "chain = classification_chain | branches\n",
    "\n",
    "# Run the chain with an example review\n",
    "# Good review - \"The product is excellent. I really enjoyed using it and found it very helpful.\"\n",
    "# Bad review - \"The product is terrible. It broke after just one use and the quality is very poor.\"\n",
    "# Neutral review - \"The product is okay. It works as expected but nothing exceptional.\"\n",
    "# Default - \"I'm not sure about the product yet. Can you tell me more about its features and benefits?\"\n",
    "\n",
    "review = \"The product is terrible. It broke after just one use and the quality is very poor.\"\n",
    "result = chain.invoke({\"feedback\": review})\n",
    "\n",
    "# Output the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM chains, Sequential Chain, Complex Sequential chain\n",
    "\n",
    "An **LLMChain** in LangChain is a fundamental chain that integrates a language model (LLM) with a prompt template. It is widely used throughout LangChain, including in other chains and agents. The primary purpose of an LLMChain is to facilitate interactions with language models by structuring the input and output in a consistent manner.\n",
    "\n",
    "A **Simple Sequential Chain** is a straightforward chain where the output of one step directly feeds into the next step. This type of chain is ideal for scenarios where each step has a single input and a single output. It’s useful for linear workflows where the sequence of operations is fixed and straightforward.\n",
    "\n",
    "Example:\n",
    "Imagine you have a process where you first translate a text and then summarize it. Here’s how you might set up a Simple Sequential Chain for this task:\n",
    "\n",
    "A **Complex Sequential Chain** allows for more sophisticated workflows where multiple inputs and outputs are handled seamlessly. This type of chain is perfect for multi-step language processing tasks that require more intricate data flow and dependencies between steps.\n",
    "\n",
    "Example:\n",
    "Consider a scenario where you need to translate a review, summarize it, detect the language of the original review, and generate a follow-up response based on the summary and detected language. Here’s how you might set up a Complex Sequential Chain for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Tamil Nadu', 'output': '\\nHere are two sentences based on the information provided:\\n1. Chennai, formerly known as Madras, is the fourth largest city in India, situated on the Coromandel Coast of the Bay of Bengal, and is celebrated for its temples, beaches, and significant role as a cultural, economic, and educational hub in South India.\\n2. The capital city of Tamil Nadu, Chennai, was previously referred to as Madras, and is the fourth largest city in India, located on the Coromandel Coast of the Bay of Bengal, and renowned for its temples, beaches, and status as a major cultural, economic, and educational center in South India.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "\n",
    "# Define the individual steps\n",
    "# Translation logic here\n",
    "template1=\"\"\" \n",
    "What is the capital of {text}\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(template=template1,input_variables=['text'])\n",
    "llm_chain1=LLMChain(prompt=prompt,llm=llm,output_key='translated_text')\n",
    "\n",
    "\n",
    "# Summarization logic here\n",
    "template2=\"\"\" \n",
    "Give 2 senetences about famous items in {text}\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(template=template2,input_variables=['translated_text'])\n",
    "llm_chain2=LLMChain(prompt=prompt,llm=llm,output_key='summarize_text')\n",
    "\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[llm_chain1, llm_chain2])\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke(\"Tamil Nadu\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Review': 'Les ordinateurs portables GamersTech impressionne par ses performances exceptionnelles et son design élégant. De sa configuration matérielle robuste à un clavier RVB personnalisable et un système de refroidissement efficace, il établit un équilibre parfait entre prouesses de jeu et portabilité.',\n",
       " 'translate': \" Le poids et la taille de ce portable sont parfaits pour être emporté à l'extérieur, tout en offrant une expérience de jeu sans faille. Les jeux les plus exigeants s'exécutent sans problème, et les graphiques sont magnifiques. Les batteries durables offrent une autonomie impressionnante, ce qui permet de jouer pendant des heures sans se soucier de l'alimentation. Les connectivités sont nombreuses et variées, permettant d'utiliser tous les périphériques préférés. Enfin, le prix est très compétitif, ce qui rend GamersTech un choix idéal pour les joueurs à la recherche d'un ordinateur portable puissant et performant.\\n\\nEnglish translation:\\n\\nGamersTech impresses with its exceptional performance and elegant design. From its robust hardware configuration to a customizable RGB keyboard and effective cooling system, it strikes the perfect balance between gaming prowess and portability. Its weight and size are ideal for carrying outside while offering a faultless gaming experience. Demanding games run smoothly, and graphics are stunning. Durable batteries offer impressive autonomy, allowing for hours of play without worrying about power. Connectivity options are plentiful and varied, enabling the use of preferred peripherals. Lastly, the price is very competitive, making GamersTech an excellent choice for gamers seeking a powerful and high-performing portable computer.\",\n",
       " 'summerize': '',\n",
       " 'title': \" of this article and write a 2-3 sentence summary of the main points of the article.\\n\\nTitle: The Importance of Social Media in Today's Business World\\n\\nSummary: This article emphasizes the significance of social media in modern business, discussing how it enables companies to connect with customers, build brand awareness, and respond to feedback in real-time. It also highlights the various social media platforms, such as Facebook, Twitter, and LinkedIn, and their unique features that cater to different business needs. Overall, social media has become an indispensable tool for businesses looking to engage with their audience, stay competitive, and grow in today's digital age.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.sequential import SequentialChain\n",
    "Review = 'Les ordinateurs portables GamersTech impressionne par ses performances exceptionnelles et son design élégant. De sa configuration matérielle robuste à un clavier RVB personnalisable et un système de refroidissement efficace, il établit un équilibre parfait entre prouesses de jeu et portabilité.'\n",
    "\n",
    "\n",
    "prompt_template1= PromptTemplate.from_template('Translate the review in english {Review}')\n",
    "chain1= LLMChain(llm=llm, prompt=prompt_template1,output_key='translate')\n",
    "prompt_template2= PromptTemplate.from_template('Summerize the content in 2 senetnces {translate}')\n",
    "chain2= LLMChain(llm=llm, prompt=prompt_template2,output_key='summerize')\n",
    "prompt_template3= PromptTemplate.from_template('Give a title to the summerization {summerize}')\n",
    "chain3= LLMChain(llm=llm, prompt=prompt_template3,output_key='title')\n",
    "\n",
    "\n",
    "sschain=SequentialChain(chains=[chain1,chain2,chain3],\n",
    "                        input_variables=[\"Review\"],\n",
    "                        output_variables=[\"translate\",\"summerize\",\"title\"])\n",
    "\n",
    "sschain.invoke(Review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router chain\n",
    "\n",
    "In LangChain, a RouterChain is a specialized type of chain designed to dynamically route inputs to different subchains based on specific criteria or conditions. This allows for more complex and flexible workflows where the path of execution can change depending on the input data.\n",
    "\n",
    "Key Features of RouterChain\n",
    "\n",
    "Dynamic Routing:\n",
    "\n",
    "RouterChain enables non-deterministic execution paths, meaning the next step in the chain can vary based on the input or the output of previous steps.\n",
    "\n",
    "Conditional Logic:\n",
    "\n",
    "It incorporates conditional logic to decide which subchain to execute. This can be based on various factors such as the content of the input, the results of previous computations, or external conditions.\n",
    "\n",
    "Integration with RunnableLambda and RunnableBranch:\n",
    "\n",
    "RouterChain can use RunnableLambda to conditionally return different runnables (subchains) based on the input.\n",
    "It can also use RunnableBranch to handle more complex branching logic.\n",
    "\n",
    "Example Use Case\n",
    "\n",
    "Imagine you have a system that needs to handle different types of user queries, such as questions about LangChain, Anthropic, or general queries. A RouterChain can be used to route these queries to the appropriate subchain for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomRouterChain' object has no attribute 'router'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 53\u001b[0m\n\u001b[0;32m     43\u001b[0m router_chain \u001b[38;5;241m=\u001b[39m CustomRouterChain(\n\u001b[0;32m     44\u001b[0m     router\u001b[38;5;241m=\u001b[39mRunnableLambda(route_logic),\n\u001b[0;32m     45\u001b[0m     chains\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     }\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Run the RouterChain with an input\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrouter_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow do I use LangChain?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\dkavy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\dkavy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[17], line 35\u001b[0m, in \u001b[0;36mCustomRouterChain._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m---> 35\u001b[0m     chain_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrouter\u001b[49m(inputs)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchainschain_name\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomRouterChain' object has no attribute 'router'"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router import RouterChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define the routing logic\n",
    "def route_logic(input_data):\n",
    "    if \"langchain\" in input_data[\"question\"].lower():\n",
    "        return \"langchain_chain\"\n",
    "    elif \"anthropic\" in input_data[\"question\"].lower():\n",
    "        return \"anthropic_chain\"\n",
    "    else:\n",
    "        return \"general_chain\"\n",
    "\n",
    "\n",
    "langchain_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(\"You are an expert in LangChain. Answer the following question: {question}\")\n",
    ")\n",
    "\n",
    "anthropic_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(\"You are an expert in Anthropic. Answer the following question: {question}\")\n",
    ")\n",
    "\n",
    "general_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(\"Answer the following question: {question}\")\n",
    ")\n",
    "\n",
    "# Create a subclass of RouterChain and implement the abstract methods\n",
    "class CustomRouterChain(RouterChain):\n",
    "    def _call(self, inputs):\n",
    "        chain_name = self.router(inputs)\n",
    "        return self.chainschain_name\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"question\"]\n",
    "\n",
    "# Instantiate the CustomRouterChain\n",
    "router_chain = CustomRouterChain(\n",
    "    router=RunnableLambda(route_logic),\n",
    "    chains={\n",
    "        \"langchain_chain\": langchain_chain,\n",
    "        \"anthropic_chain\": anthropic_chain,\n",
    "        \"general_chain\": general_chain\n",
    "    }\n",
    ")\n",
    "\n",
    "# Run the RouterChain with an input\n",
    "result = router_chain.invoke({\"question\": \"How do I use LangChain?\"})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
